--
layout:     post # 使用的布局（不需要改）
title:      感知机           # 标题 
subtitle:   统计学习方法(chap 2) #副标题
date:       2018-03-19              # 时间
author:     储颖君                  # 作者
header-img: img/post-bg-universe.jpg   #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 统计学习方法
---

###### 序
> 感知机是一个二类分类的线性分类器：其输入实例的特征向量，输出为实例的类别，取+1和-1二值。
感知机对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面，属于判别模型。

### 感知机模型
感知机模型如下：

```math
f(x) = sign(w * x + b)
```
其中：
```math
sign(x) = \begin{cases}  
+1, & x \geq 0 \\
-1, & x < 0
\end{cases}
```
这是一种线性分类模型，属于判别模型。
***
###### 几何解释：
线性方程 w*x+b对应于特征空间的一个超平面S,其中w是超平面的法向量，b是超平面的截距。这个超平面将特征空间划分为两个部分。位于两部分的点（特征向量）分别被分为正、负两类。因此，超平面S称为分离超平面。

![image](https://github.com/chuyingjun/myPostImg/blob/master/picture/1.png?raw=true)

### 感知机学习策略：

##### 数据集的线性可分性：
![image](https://github.com/chuyingjun/myPostImg/blob/master/picture/2.png?raw=true)

感知机的学习目标是求得一个能够将训练集正实例点和负实例点完全正确分开的分离超平面。为了找出这样的超平面，即确定感知机模型参数w，b，需要确定一个学习策略，即定义（经验）损失函数并将损失函数极小化。

损失函数：
* 损失函数的一个自然选择是误分类点的总数，但是这样的损失函数不是参数w，b的连续可导函数，不易优化。
* 损失函数的另一个选择是误分类点到超平面S的总距离，这是感知机所采用的。
***
### 损失函数
![image](https://github.com/chuyingjun/myPostImg/blob/master/picture/3.png?raw=true)

***
### 感知机学习算法
感知机学习问题转化为求解损失函数式的最优化问题，最优化的方法是随机梯度下降法。

##### 感知机学习算法的原始形式
![image](https://github.com/chuyingjun/myPostImg/blob/master/picture/4.png?raw=true)
感知机学习算法是误分类驱动的，具体采用随机梯度下降法。首先随机选取一个超平面W0,b0,然后用梯度下降发不断地极小化目标函数。极小化过程中不是一次使M中所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降。
![image](https://github.com/chuyingjun/myPostImg/blob/master/picture/5.png?raw=true)

##### 感知机学习算法的对偶形式

![image](https://note.youdao.com/favicon.ico)